{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **딥러닝**\n",
        "\n",
        "딥러닝 모델 종류\n",
        "  + Sequential 모델\n",
        "    - DNN: 기본적인 딥러닝 모델\n",
        "    - CNN: 사진, 영상 딥러닝 모델\n",
        "    - RNN: 시계열, 자연어처리 딥러닝 모델\n",
        "    - AutoEncoder: 특징 추출 딥러닝 모델\n",
        "    - GAN: 생성형 딥러닝 모델\n",
        "    - Stable Difussion: New 생성형 딥러닝 모델\n",
        "\n",
        "  + Transformer 모델\n",
        "    - BERT(Google)\n",
        "    - GPT(OpenAI)"
      ],
      "metadata": {
        "id": "4jefHuc91uAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MNIST 데이터를 활용한 (숫자)손글씨 분류**\n",
        "\n",
        " - 데이터: MNIST\n",
        "   + 0~9까지의 손글씨 이미지 데이터\n",
        "   + 1장의 이미지는 28x28 구성(기본)\n",
        "   + 흑백(1픽셀: 0~255)\n",
        "   + Train: 60,000장, Test: 10,000장\n",
        " - 데이터 변환: 정규화(Normalization)\n",
        "   + Min-Max Scaler\n",
        " - 모델: CNN(2d)\n",
        " - 평가: Accuracy, F1-score, Confusion Matrix\n",
        " - 채널이 x1이면 흑백, x3이면 RGB"
      ],
      "metadata": {
        "id": "XnSFOeCm2SWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 모듈 로드"
      ],
      "metadata": {
        "id": "3NI6NIxMuAXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. **torch**  \n",
        "   - PyTorch의 핵심 패키지로, 텐서 연산, 자동 미분, 신경망을 구성하고 학습하는 데 사용\n",
        "\n",
        "b. **torch.nn as nn**  \n",
        "   - 신경망을 구성하는 레이어, 손실 함수 등을 포함한 모듈로, `nn.Module` 클래스를 상속받아 딥러닝 모델의 구조를 정의하는 데 사용.\n",
        "\n",
        "c. **torch.optim as optim**  \n",
        "   - 모델 학습을 위한 최적화 알고리즘(SGD, Adam 등)이 들어 있는 모듈로, 학습 도중 가중치를 업데이트하는 데 사용\n",
        "\n",
        "d. **torch.nn.functional as F**  \n",
        "   - 다양한 신경망 함수들을 제공하며, 활성화 함수(ReLU)나 손실 함수 등을 모델 내부에서 호출하는 데 사용\n",
        "\n",
        "e. **torchvision.datasets**  \n",
        "   - 컴퓨터 비전에서 자주 사용되는 이미지 데이터셋(MNIST, CIFAR-10 등)을 불러오는 데 사용\n",
        "\n",
        "f. **torchvision.transforms**  \n",
        "   - 이미지 데이터에 정규화, 리사이즈 등의 전처리 작업을 적용하는 데 사용\n",
        "\n",
        "g. **matplotlib.pyplot as plt**  \n",
        "   - 손실 함수의 변화나 이미지 데이터를 시각적으로 보여줄 때 시각화를 위한 모듈로 사용\n",
        "\n",
        "h. **torch.utils.data.DataLoader**  \n",
        "   - 데이터셋을 배치 단위로 나누어 학습할 수 있게 해주는 모듈로, 메모리 효율성을 높이고 학습 속도를 증가시키기 위해 사용\n",
        "\n",
        "i. **torch.utils.data.random_split**  \n",
        "   - 주어진 데이터셋을 훈련용과 검증용으로 랜덤하게 나누는 데 사용\n"
      ],
      "metadata": {
        "id": "RGUqBdtRRuqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPFmSP7XupW2",
        "outputId": "8e713133-b87b-4c74-97de-dbfd4679d428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57boeRlvthOq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 데이터셋 다운로드 및 확인"
      ],
      "metadata": {
        "id": "3o3up4ftuONu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **데이터셋 로드 및 전처리**\n",
        "\n",
        "`transforms.Compose`를 사용하여 **이미지 데이터를 텐서(Tensor)로 변환**하고, **정규화(Normalization)**를 적용 (\n",
        " MNIST 데이터는 픽셀 값이 0~255 사이인데, 이를 -1에서 1 사이로 변환하여 모델 학습에 더 적합하게 만듦)  \n",
        "\n",
        "`datasets.MNIST`를 사용해 **MNIST 데이터셋을 다운로드**하고, 훈련용(`train=True`)과 테스트용(`train=False`)으로 각각 로드함\n",
        "\n",
        "\n",
        "\n",
        "* 데이터 로더 생성\n",
        "\n",
        "`torch.utils.data.DataLoader`를 사용하여 **데이터셋을 배치 단위로 나누어 로딩**함. 훈련 데이터는 배치 크기 64로 설정하고 **셔플(Shuffle)**하여 데이터를 섞은 후, 모델이 항상 같은 순서로 학습하지 않도록 함. 테스트 데이터는 셔플하지 않고 배치 단위로 로딩함.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **학습 데이터 확인**\n",
        "\n",
        "`iter(train_loader)`를 통해 **학습 데이터에서 첫 번째 배치**를 가져옴. 이 배치에서 **이미지와 라벨**을 확인할 수 있었음.\n",
        "\n",
        "\n",
        "* 첫 번째 이미지 시각화\n",
        "\n",
        "가져온 학습 데이터의 첫 번째 이미지를 **matplotlib의 imshow 함수**를 사용해 흑백(`cmap='gray'`)으로 시각화함. **라벨**(숫자가 무엇인지)도 함께 표시하여, 이미지와 실제 값이 무엇인지를 확인함.\n",
        "\n",
        "\n",
        "*  데이터 크기 확인\n",
        "`len(train_set)`과 `len(test_set)`을 통해 **훈련 데이터와 테스트 데이터의 총 이미지 개수**를 출력함. 훈련 데이터는 60,000장, 테스트 데이터는 10,000장으로 구성되어 있음을 확인할 수 있었음.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hqOOHkRfTcoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로드\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# 데이터 로더 생성\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ugjxahKhuNO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 확인\n",
        "data_iter = iter(train_loader)\n",
        "images, labels = next(data_iter)\n",
        "\n",
        "# 첫 번째 이미지 시각화\n",
        "plt.imshow(images[0][0], cmap='gray')\n",
        "plt.title(f\"Label: {labels[0]}\")\n",
        "plt.show()\n",
        "\n",
        "# 데이터 크기 확인\n",
        "print(f\"학습 데이터 크기: {len(train_set)}\")\n",
        "print(f\"테스트 데이터 크기: {len(test_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "DsF8-N7XwZud",
        "outputId": "a9e29be9-4053-4a83-d288-82a73f0bb9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기: 60000\n",
            "테스트 데이터 크기: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 데이터 정규화"
      ],
      "metadata": {
        "id": "uO9ZgbqXxuh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터와 테스트 데이터를 0~1 사이로 정규화\n",
        "x_train = train_set.data.float() / 255\n",
        "x_test = test_set.data.float() / 255\n",
        "\n",
        "# 데이터의 Shape 변환\n",
        "# CNN을 위한 4차원으로 변환 (batch_size, channels, height, width)\n",
        "x_train = x_train.unsqueeze(1)  # 채널 1 추가\n",
        "x_test = x_test.unsqueeze(1)    # 채널 1 추가\n",
        "\n",
        "print(x_train.shape)  # (60000, 1, 28, 28)\n",
        "print(x_test.shape)   # (10000, 1, 28, 28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkzcVoN-xpFx",
        "outputId": "b85367a9-be39-43e6-eea3-e592a506ab06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. 검증 데이터 (validation data) 생성"
      ],
      "metadata": {
        "id": "4pWxkPqIx9OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 데이터의 80%를 학습, 20%를 검증으로 나눔\n",
        "train_size = int(0.8 * len(train_set))\n",
        "valid_size = len(train_set) - train_size\n",
        "\n",
        "# Train(48,000), Valid(12,000)\n",
        "train_set, valid_set = random_split(train_set, [train_size, valid_size])\n",
        "\n",
        "# 학습 데이터와 검증 데이터의 크기 확인\n",
        "print(f\"Train data size: {len(train_set)}\")\n",
        "print(f\"Validation data size: {len(valid_set)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBilLyMDx7dV",
        "outputId": "364b6069-236e-4545-b7ff-ccb02ede6403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size: 48000\n",
            "Validation data size: 12000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 딥러닝(CNN) 모델 설계"
      ],
      "metadata": {
        "id": "O1aCFOUbyO2n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 합성곱 레이어 및 풀링 레이어\n",
        "* conv1: 첫 번째 합성곱 레이어로, 1채널(흑백) 이미지를 입력받아 16개의 필터를 사용해 처리함. 커널 크기는 5x5이며, 패딩을 2로 설정해 출력 크기를 유지함.\n",
        "* pool: Max Pooling 레이어로, 2x2 크기의 풀링 필터를 사용하여 이미지 크기를 절반으로 줄임.\n",
        "* conv2: 두 번째 합성곱 레이어로, 16개의 입력 채널을 받아 32개의 필터를 출력함. 커널 크기는 2x2이고, 패딩은 1임.\n"
      ],
      "metadata": {
        "id": "H6gdYpFhap2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 완전 연결 레이어 및 드롭아웃\n",
        "\n",
        "* fc1: 첫 번째 완전 연결 레이어로, 합성곱 레이어와 풀링 과정을 거친 32채널의 7x7 크기의 데이터를 100개의 뉴런으로 연결함.\n",
        "* fc2: 두 번째 완전 연결 레이어로, 100개의 뉴런을 10개의 출력(0~9 손글씨 숫자 분류)으로 변환함.\n",
        "* dropout: 과적합을 방지하기 위해 학습 과정에서 25%의 뉴런을 무작위로 제거함.\n"
      ],
      "metadata": {
        "id": "aEou1zdCbCNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 순전파 과정\n",
        "\n",
        "* **첫 번째 합성곱(conv1)과 풀링(pool)**을 통해 이미지의 주요 특징을 추출한 후 ReLU 활성화 함수를 사용해 비선형성을 적용함.\n",
        "* 두 번째 합성곱(conv2)과 풀링을 거쳐 데이터를 평탄화(flatten) 하여 2D 이미지를 1D 벡터로 변환함.\n",
        "* **완전 연결 레이어(fc1)**를 통과시킨 후, 드롭아웃을 적용해 과적합을 방지하고, fc2에서 최종 출력을 도출함."
      ],
      "metadata": {
        "id": "Q-2bk6zzbNYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNNModel 클래스를 사용해 모델을 초기화하고, print(model)을 통해 CNN 모델의 전체 구조를 확인할 수 있음."
      ],
      "metadata": {
        "id": "x8zxJ8EpbZyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=2, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 7 * 7, 100)\n",
        "        self.fc2 = nn.Linear(100, 10)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 7 * 7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "model = CNNModel()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EIid3zqyV09",
        "outputId": "056fb576-75f1-41bb-93d9-011a8748fdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNModel(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=1568, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. 딥러닝 모델 학습을 위한 설정"
      ],
      "metadata": {
        "id": "eklKcjK4yVc6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 손실 함수(Criterion): CrossEntropyLoss는 분류 문제에서 사용되는 손실 함수로, 모델이 예측한 값과 실제 정답 사이의 차이를 계산하여 모델의 성능을 평가하는 데 사용됨.\n",
        "\n",
        "* 최적화 함수(Optimizer): Adam 옵티마이저는 가중치 업데이트를 효율적으로 하기 위한 최적화 알고리즘으로, 학습률(lr)은 0.001로 설정함. Adam은 SGD보다 빠르고 적응적인 학습이 가능함."
      ],
      "metadata": {
        "id": "S7nfqbHYbm2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Early Stopping: 모델이 학습 중 과적합을 방지하기 위해, 성능이 개선되지 않으면 학습을 조기에 중단하는 방법. **patience**는 성능이 개선되지 않아도 기다리는 횟수를 의미하며, 여기서는 3번으로 설정됨.\n",
        "\n",
        "* best_loss: 현재까지 가장 낮은 손실 값을 저장하기 위한 변수로, 초기값은 무한대로 설정됨.\n",
        "\n",
        "* early_stopping_counter: 성능 개선이 이루어지지 않은 에포크 수를 추적하는 변수로, 이 값이 early_stopping_patience를 초과하면 학습이 중단됨."
      ],
      "metadata": {
        "id": "KT62denzbuAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실 함수와 최적화 함수 정의\n",
        "criterion = nn.CrossEntropyLoss()  # 분류 문제이므로 CrossEntropyLoss 사용\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer 사용\n",
        "\n",
        "# Early Stopping을 위한 변수 설정\n",
        "early_stopping_patience = 3\n",
        "best_loss = float('inf')\n",
        "early_stopping_counter = 0"
      ],
      "metadata": {
        "id": "yWuJPqknynWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. 딥러닝 모델 학습"
      ],
      "metadata": {
        "id": "iSYtl0xKy0Nk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Epoch 반복: num_epochs = 5로 설정하여 모델을 5번 반복해서 학습시킴. epoch은 전체 학습 데이터가 한 번씩 모델을 통과하는 과정임.\n",
        "\n",
        "* 모델 학습 모드: model.train()을 호출하여 모델을 학습 모드로 전환함. 이 모드에서는 드롭아웃과 같은 레이어가 활성화됨.\n",
        "\n",
        "* 경사 초기화: optimizer.zero_grad()를 사용해 이전 배치에서 계산된 경사를 초기화함.\n",
        "\n",
        "* 순전파: 입력 데이터를 모델에 넣어 예측값(outputs)을 생성함.\n",
        "\n",
        "* 손실 계산: criterion(CrossEntropyLoss)을 사용해 모델의 예측값과 실제 라벨(labels) 간의 **손실(loss)**을 계산함.\n",
        "\n",
        "* 역전파: loss.backward()를 호출하여 역전파를 통해 경사를 계산하고, 모델의 파라미터에 대한 그래디언트를 계산함.\n",
        "\n",
        "* 가중치 갱신: optimizer.step()을 호출하여 경사 하강법을 통해 가중치를 갱신함."
      ],
      "metadata": {
        "id": "7qATMY9zcD38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()  # 경사 초기화\n",
        "        outputs = model(inputs)  # 순전파\n",
        "        loss = criterion(outputs, labels)  # 손실 계산\n",
        "        loss.backward()  # 역전파\n",
        "        optimizer.step()  # 가중치 갱신\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # 검증 데이터에 대한 성능 평가\n",
        "    model.eval()\n",
        "    valid_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss / len(train_loader)}, Validation Loss: {valid_loss / len(test_loader)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59-Q6dXsyy5q",
        "outputId": "21362d5c-3831-4102-b80e-10b0ab541ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Training Loss: 0.2717101652426387, Validation Loss: 0.06079215464808023\n",
            "Epoch [2/5], Training Loss: 0.0846850287436303, Validation Loss: 0.03912821759895798\n",
            "Epoch [3/5], Training Loss: 0.06393228004103713, Validation Loss: 0.033431166095675265\n",
            "Epoch [4/5], Training Loss: 0.05248750388837739, Validation Loss: 0.03671887713145879\n",
            "Epoch [5/5], Training Loss: 0.046278531305310226, Validation Loss: 0.02904873142343042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. 딥러닝 모델 평가"
      ],
      "metadata": {
        "id": "GTEX_0XC0ev-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "HnQu1hEP1VQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* torch.no_grad(): 평가 시에는 역전파를 비활성화하여 메모리와 계산 비용을 절약함.\n",
        "* torch.max(outputs, 1): 각 입력에 대해 **최대값을 가진 클래스(예측 값)**를 반환함.\n",
        "* y_pred와 y_true에 예측 값과 실제 라벨을 저장하여 성능 평가에 사용함."
      ],
      "metadata": {
        "id": "9FJ7yXnvccbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* accuracy_score: 모델의 **정확도(Accuracy)**를 계산함. 전체 예측 중 맞춘 비율을 나타냄.\n",
        "\n",
        "* Test Accuracy는 0.9898로 출력됨, 이는 모델이 테스트 데이터에서 약 98.98%의 정확도를 보였다는 의미임.\n",
        "\n",
        "* F1 스코어: 모델의 **정확도와 재현율(Recall)**을 모두 고려한 성능 지표로, 불균형한 데이터에서 더 유용함.\n",
        "\n",
        "* weighted average를 사용해 각 클래스의 비율을 고려한 F1 스코어를 계산함.\n",
        "\n",
        "* Test F1은 0.9898로 출력됨.\n",
        "\n",
        "* 혼동 행렬(Confusion Matrix): 각 클래스별로 실제 값과 예측 값의 분포를 보여줌. 혼동 행렬을 통해 모델이 어느 클래스에서 잘못 예측했는지 확인할 수 있음.\n",
        "\n",
        "* 출력된 혼동 행렬은 10개의 숫자 클래스(0~9)에 대한 예측 결과를 보여줌."
      ],
      "metadata": {
        "id": "_j9F3B_YcjeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # 모델 평가 모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 예측 및 정확도 계산\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_pred.extend(predicted.numpy())\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "\n",
        "# F1 스코어 계산\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "print(f'Test F1: {f1}')\n",
        "\n",
        "# 혼동 행렬 출력\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjfsbzEW0bpX",
        "outputId": "90309378-75ad-4b4b-f3a5-d639d55acaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9898\n",
            "Test F1: 0.9897942191412638\n",
            "Confusion Matrix:\n",
            "[[ 976    0    0    1    0    0    1    0    2    0]\n",
            " [   0 1132    1    0    0    0    1    1    0    0]\n",
            " [   2    0 1027    0    1    0    0    2    0    0]\n",
            " [   1    0    1 1000    0    3    0    3    2    0]\n",
            " [   0    0    0    0  975    0    0    0    1    6]\n",
            " [   2    0    0    2    0  884    3    0    0    1]\n",
            " [   6    5    0    0    3    3  940    0    1    0]\n",
            " [   0    1    7    1    0    0    0 1016    1    2]\n",
            " [   4    1    3    3    1    1    0    2  955    4]\n",
            " [   0    1    0    0    2    5    0    5    3  993]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**성능 결과**\n",
        "\n",
        "* 정확도(Accuracy): 98.98%로 모델이 테스트 데이터에서 매우 높은 성능을 보여줌.\n",
        "\n",
        "* F1 스코어: 0.9898로, 정확도와 재현율을 함께 고려한 성능 지표에서 높은 성능을 나타냄.\n",
        "\n",
        "* 혼동 행렬을 통해 모델이 예측을 잘한 부분과 오차가 발생한 부분을 구체적으로 확인할 수 있음.\n"
      ],
      "metadata": {
        "id": "-4gdp3HXc34z"
      }
    }
  ]
}